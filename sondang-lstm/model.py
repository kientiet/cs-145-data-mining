# <codecell> Loading librariesimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport mathfrom keras.models import Sequentialfrom keras.layers import LSTMfrom keras.layers import Dense, Dropoutfrom sklearn.preprocessing import StandardScalerimport seaborn as sns# <codecell> Loading datatrain_vaccine = pd.read_csv('train_vaccine.csv')train_trendency = pd.read_csv('train_trendency.csv')test = pd.read_csv('test.csv')# <codecell> Checking dataprint(train_trendency.dtypes)print(train_vaccine.dtypes)## Number of states in each datasetprint(train_trendency.groupby(['Date']).size())print(train_vaccine.groupby(['date']).size())## There's a mismatch in the number of statestrain_trendency.iloc[0:50, 1:2]train_vaccine.iloc[0:49, 2:3]merge_states = (pd.merge(train_trendency.iloc[0:50, 1:2],                train_vaccine.iloc[0:49, 2:3],                how="outer",                left_on=['Province_State'],                right_on=['location']))## Printing the missing state in train_vaccineprint(merge_states[merge_states['location'].isnull()])# <codecell> Convert date to correct formattrain_trendency['Date'] = pd.to_datetime(train_trendency['Date'])train_vaccine['date'] = pd.to_datetime(train_vaccine['date'])# <codecell> Chaging date column in train_vaccine to Datetrain_vaccine_1 = train_vaccine.rename(columns={'date': 'Date', 'location':'Province_State'})# <codecell> Dropping 'Recovered' and 'Active' since there are too many missing datatrain_trendency_1 = train_trendency.drop(columns = ['Recovered', 'Active'])# <codecell> Merging train_trendency and train_vaccinemerged_train = pd.merge(train_trendency_1, train_vaccine_1, on=['Province_State', 'Date'])merged_train_2 = merged_train.drop(columns = ['Unnamed: 0_y', 'Unnamed: 0_x'])# <codecell> Using data from 2021-01-19 only to avoid missing data for vaccinationmerged_train_2 = merged_train_2[merged_train_2['Date'] >= pd.to_datetime('2021-01-19', format='%Y-%m-%d')]# <codecell> Imputing missing value for vaccination on 2021-02-15states = merged_train_2['Province_State'].unique().tolist()missing_attributes = ['total_vaccinations', 'people_fully_vaccinated']missing_date = pd.to_datetime('2021-02-15', format='%Y-%m-%d')day_before = pd.to_datetime('2021-02-14', format='%Y-%m-%d')day_after = pd.to_datetime('2021-02-16', format='%Y-%m-%d')print(day_before)print(day_after)for missing_attribute in missing_attributes:    for state in states:        t_minus_1 = merged_train_2[(merged_train_2['Date'] == day_before) & (merged_train_2['Province_State'] == state)][missing_attribute].values[0]        t_plus_1 = merged_train_2[(merged_train_2['Date'] == day_after) & (merged_train_2['Province_State'] == state)][missing_attribute].values[0]        t = math.floor((t_minus_1 + t_plus_1)/2)        merged_train_2.loc[(merged_train_2['Date'] == missing_date) & (merged_train_2['Province_State'] == state), missing_attribute] = t# <codecell> Testexample = merged_train_2[merged_train_2['Province_State'] == 'Alabama']plt.plot(example['Deaths'], example['Date'])# <codecell> Scalingdf_scaler = StandardScaler()df_scaler = df_scaler.fit(example.iloc[:, 4:10])scaled_df = df_scaler.transform(example.iloc[:, 4:10])death_scaler = StandardScaler()death_scaler = death_scaler.fit(example.iloc[:, 3:4])scaled_death = death_scaler.transform(example.iloc[:, 3:4])confirmed_scaler = StandardScaler()confirmed_scaler = confirmed_scaler.fit(example.iloc[:, 2:3])scaled_confirmed = confirmed_scaler.transform(example.iloc[:, 2:3])# <codecell> Reshape input datadeath_df = np.append(scaled_df, scaled_death, 1)trainX = []trainY = []obs_point = 30for i in range(obs_point, len(scaled_df)):    trainX.append(death_df[i - obs_point: i, :])    trainY.append(death_df[i:i + 1, 6])    trainX = np.array(trainX)trainY = np.array(trainY)# <codecell> Modelmodel = Sequential()model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))model.add(LSTM(32, activation='relu', return_sequences=False))model.add(Dropout(0.2))model.add(Dense(trainY.shape[1]))model.compile(optimizer='adam', loss='mse')model.summary()# <codecell> Fitting modelhistory = model.fit(trainX, trainY, epochs=10, batch_size=7, validation_split=0.1, verbose=1)# <codecell> Forecastingforecast_start_date = pd.to_datetime('2021-04-01', format='%Y-%m-%d')forecast_period_dates = pd.date_range(forecast_start_date, periods=30, freq='1d').tolist()forecast = model.predict(trainX[-30:])y_pred_future = np.floor(death_scaler.inverse_transform(forecast))df_forecast = pd.DataFrame({'Date':forecast_period_dates, 'Deaths':y_pred_future.flatten()})training_start_date = pd.to_datetime('2021-02-18', format='%Y-%m-%d')training_period_dates = pd.date_range(training_start_date, periods=42, freq='1d').tolist()training_pred = model.predict(trainX)training_pred_scaled = np.floor(death_scaler.inverse_transform(training_pred))# <codecell> Plotting# =============================================================================# sns.lineplot(example['Deaths'], example['Date'])# sns.lineplot(df_forecast['Deaths'], df_forecast['Date'])# =============================================================================plt.figure(figsize=(12,8))plt.plot(example['Date'], example['Deaths'], label='Training', color = 'green')plt.plot(df_forecast['Date'], df_forecast['Deaths'], label='Forecasting', color = 'yellow')plt.legend(loc='upper right')plt.show()# <codecell> test2## we can see that all the variables are highly correlated with each other so it would ## not be helpful to include others variables in our modelcorrMatrix = example.corr()sns.heatmap(corrMatrix, annot = True)plt.show()